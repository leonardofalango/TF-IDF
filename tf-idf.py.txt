# Leonardo Falango
# O colab não esta funcionando nos computadores da PUC
# Entao estou enviando pelo github mesmo


from bs4 import BeautifulSoup
from requests_html import HTMLSession
import spacy
import pandas as pd
import numpy as np

session = HTMLSession() # Criando a sessão
# settando os sites que iremos usar
sites = ['https://hbr.org/2022/04/the-power-of-natural-language-processing',
         'https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1',
         'https://academic.oup.com/jamia/article/18/5/544/829676?login=false',
         'https://path.com.br/noticias/o-que-e-natural-language-processing/',
         'https://www.lexalytics.com/blog/machine-learning-natural-language-processing/']

matrix = []

for site in sites:
  r = session.get(site) # Acessando os sites
  req = r.content
  soup = BeautifulSoup(req, 'html.parser')

  all_text = soup.find_all('p')# Pegando todos os <p>{conteúdo}</p> do site
  
  nlp = spacy.load("en_core_web_sm") # Usando o spacy
  all_sents = []
  
  for txt in all_text:
    doc = txt.get_text()
    document = nlp(doc).sents
    
    for doc in document:
      all_sents.append(doc)
  
  
  
  # Criando um vetor que o conteúdo é uma matrix, e o vetor 0
  # é o primeiro site, o vetor 1 é o segundo site....
  

  # Para organizar os sites tem como fazer em dicionário.

  matrix.append(all_sents)

site0 = matrix[0]
site1 = matrix[1]
site2 = matrix[2]
site3 = matrix[3]
site4 = matrix[4]

from string import punctuation

vocabulario = []
for site in matrix:
  for sentence in site:
    palavras = sentence.text.split(" ")
    for palavra in palavras:
      vocabulario.append(palavra.strip(punctuation).replace("\n", "").replace('"', '').replace("'", "").lower())

vocabulario = list(set(vocabulario))

dicionario = {}
dicionario['Palavra'] = vocabulario

dicionario_maiorzao = {}
for site in matrix:
    for sentence in site:
        lista = []
        just_another_list = []
        just_another_another_list = []
        for palavra in vocabulario:
            cont = 0
            for palavra_comp in sentence:
                if palavra_comp.text.lower() == palavra:
                    cont += 1
            lista.append(cont)
            just_another_list.append(cont / len(sentence))
            if cont != 0:
                just_another_another_list.append(len(sentence) / cont)
            else: just_another_another_list.append(1)
            
        dicionario['TF'] = just_another_list
        dicionario['QuantidadeTermo'] = lista
        dicionario['Sentenca'] = sentence.text.strip()
        dicionario['IDF'] = np.log(just_another_another_list)
        
        df = pd.DataFrame(dicionario)
    dicionario_maiorzao[sentence.text.strip()] = df





